{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Reviews Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a class Review!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    POSITIVE = 'POSITIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score    \n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score >=4:\n",
    "            return Sentiment.POSITIVE\n",
    "        else:\n",
    "            return Sentiment.NEUTRAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "Let's import the json data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!\n",
      "4.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = './dataset/Books_small.json'\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "\n",
    "print(reviews[5].text)\n",
    "print(reviews[5].score)\n",
    "print(reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep Data\n",
    "The machine models love numerical data rather than text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down. 5.0 POSITIVE\n"
     ]
    }
   ],
   "source": [
    "print(train[0].text, train[0].score, train[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "train_x = [x.text for x in train]\n",
    "train_y = [x.sentiment for x in train]\n",
    "\n",
    "test_x = [x.text for x in test]\n",
    "test_y = [x.sentiment for x in test]\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# vectorizer.fit(train_x)\n",
    "# vectorizer.transform(train_x) ---> SAME AS V\n",
    "\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "# Don't fit the the vectorizer again to test_x\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "train_x_vectors[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Cunningham mesmerizes with the thoughtful, elegant prose that is this book.  The reader becomes so close to its characters...the reader feels what these brothers feel.  Beautiful and tragic...a book that will stay with me for a long, long time.  Thank you again, Mr. Cunningham.  The Hours remains at the top of my list and The Snow Queen is another gift to your readers.\n",
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "n=2\n",
    "print(test_x[n])\n",
    "print(test_y[n])\n",
    "\n",
    "clf_svm.predict(test_x_vectors[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review of innovation techniques and examples of their application to healthcare problems is absolutely amazing!  The Lean, on the other hand, is sketchy and not convincing.  Still, an informative and a well-written book.\n",
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "\n",
    "n=42\n",
    "print(test_x[n])\n",
    "print(test_y[n])\n",
    "\n",
    "clf_dec.predict(test_x_vectors[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An intriguing book, but I am ashamed to admit I sometimes did not fully comprehend what was said, particularly when Chesterton referred to other people (writers) that I am not knowledgeable of.  At any rate a good read.\n",
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "# Dense data should be passed and not a Sparse matrix\n",
    "clf_gnb.fit(train_x_vectors.toarray(), train_y) \n",
    "\n",
    "\n",
    "n=5\n",
    "print(test_x[n])\n",
    "print(test_y[n])\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[n].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this book.  It was very interesting to hear the background involved in training a helper dog and Luis's background in the service.  I learned a lot, but was entertained at the same time.  Of course, I have a a Golden Retriever myself, so I may be biased, but mine is as dumb as a brick!  Great book.\n",
      "POSITIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinjoy/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y) \n",
    "\n",
    "\n",
    "n=6\n",
    "print(test_x[n])\n",
    "print(test_y[n])\n",
    "\n",
    "clf_log.predict(test_x_vectors[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8242424242424242\n",
      "0.7515151515151515\n",
      "0.8121212121212121\n",
      "0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuraies \n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors.toarray(), test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE', 'NEUTRAL', 'NEGATIVE']\n",
      "[0.91319444 0.21052632 0.22222222]\n",
      "[0.85815603 0.14925373 0.06896552]\n",
      "[0.89678511 0.08510638 0.09090909]\n",
      "[0.91370558 0.12244898 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]\n",
    "print(labels)\n",
    "\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=labels))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, labels=labels))\n",
    "print(f1_score(test_y, clf_gnb.predict(test_x_vectors.toarray()), average=None, labels=labels))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average=None, labels=labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the models predict POSITIVE correctly but NEUTRAL and NEGATIVE are bad!!\n",
    "Let's find out why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n",
      "552 0.8238805970149253\n",
      "71 0.10597014925373134\n",
      "47 0.07014925373134329\n"
     ]
    }
   ],
   "source": [
    "print(len(train_y))\n",
    "print(train_y.count(Sentiment.POSITIVE),train_y.count(Sentiment.POSITIVE)/len(train_y))\n",
    "print(train_y.count(Sentiment.NEUTRAL),train_y.count(Sentiment.NEUTRAL)/len(train_y))\n",
    "print(train_y.count(Sentiment.NEGATIVE),train_y.count(Sentiment.NEGATIVE)/len(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that there are around 82\\% POSITIVEs in the training data. Thus, our models will be heavily biased towards POSITIVE.\n",
    "Now, there are only 47 NEUTRALs in this data. To balance the dataset, wewill either need to make all three classes around 47 data points each (which is too small for a dataset) OR..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GET A BIGGER DATASET!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hoped for Mia to have some peace in this book, but her story is so real and raw.  Broken World was so touching and emotional because you go from Mia's trauma to her trying to cope.  I love the way the story displays how there is no \"just bouncing back\" from being sexually assaulted.  Mia showed us how those demons come for you every day and how sometimes they best you. I was so in the moment with Broken World and hurt with Mia because she was surrounded by people but so alone and I understood her feelings.  I found myself wishing I could give her some of my courage and strength or even just to be there for her.  Thank you Lizzy for putting a great character's voice on a strong subject and making it so that other peoples story may be heard through Mia's.\n",
      "5.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "file_name = './dataset/Books_small_10000.json'\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "\n",
    "print(reviews[5].text)\n",
    "print(reviews[5].score)\n",
    "print(reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evenly distribute positives and negatives   \n",
    "import random\n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "    \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "    \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))      \n",
    "#         print(len(negative))\n",
    "#         print(len(positive))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note to Self:  Do for NEUTRAL as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "5611\n",
      "208\n",
      "2767\n",
      "872\n",
      "416\n"
     ]
    }
   ],
   "source": [
    "train_cont = ReviewContainer(train)\n",
    "test_cont = ReviewContainer(test)\n",
    "\n",
    "train_cont.evenly_distribute() # If test data is not evenly dist. then\n",
    "test_cont.evenly_distribute()  # the NEGATIVE F1 score doesn't improve. WHY??\n",
    "\n",
    "print(len(train_cont.reviews))\n",
    "print(len(test_cont.reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "train_x = train_cont.get_text()\n",
    "train_y = train_cont.get_sentiment()\n",
    "\n",
    "test_x = test_cont.get_text()\n",
    "test_y = test_cont.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872\n",
      "436 0.5\n",
      "0 0.0\n",
      "436 0.5\n"
     ]
    }
   ],
   "source": [
    "print(len(train_y))\n",
    "print(train_y.count(Sentiment.POSITIVE),train_y.count(Sentiment.POSITIVE)/len(train_y))\n",
    "print(train_y.count(Sentiment.NEUTRAL),train_y.count(Sentiment.NEUTRAL)/len(train_y))\n",
    "print(train_y.count(Sentiment.NEGATIVE),train_y.count(Sentiment.NEGATIVE)/len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n",
      "208 0.5\n",
      "0 0.0\n",
      "208 0.5\n"
     ]
    }
   ],
   "source": [
    "print(len(test_y))\n",
    "print(test_y.count(Sentiment.POSITIVE),test_y.count(Sentiment.POSITIVE)/len(test_y))\n",
    "print(test_y.count(Sentiment.NEUTRAL),test_y.count(Sentiment.NEUTRAL)/len(test_y))\n",
    "print(test_y.count(Sentiment.NEGATIVE),test_y.count(Sentiment.NEGATIVE)/len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "# Don't fit the the vectorizer again to test_x\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "train_x_vectors[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a good book . The story and the characters came together nicely and the ending was awesome .\n",
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "n=2\n",
    "print(test_x[n])\n",
    "print(test_y[n])\n",
    "\n",
    "clf_svm.predict(test_x_vectors[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I choose this book because I enjoy books about the 2nd world war.  Great reading and another &#34;can't put the book down.&#34; I reccommend it to all that is into this subject.\n",
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "\n",
    "n=42\n",
    "print(test_x[n])\n",
    "print(test_y[n])\n",
    "\n",
    "clf_dec.predict(test_x_vectors[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robin writes such wondrous feel-good romances! I love them! When I pick up one of her books, I know that I will be in for a wonderful, enjoyable read.Yours at Midnight was a treat. Lyric and Quinn are wonderful characters. Quinn is our tortured hero who has been in love with Lyric since childhood. But... Lyric was besties with Quinn's brother. The three of them as next-door neighbors made a lot of memories through the years.Quinn's brother has now tragically passed away. Quinn has been away from home having left shortly after his brother's funeral. He hasn't seen or talked to Lyric in all that time, and he has an apology to make to her. Lyric has a few big secrets of her own. LOL! I wanted to shake her more than once!I connected immediately to both Lyric and Quinn. They're both survivors; each was stubborn and strong. The book's supporting characters and the setting as the time line neared New Year's Eve were perfect. I couldn't put the book down as Lyric's and Quinn's re-developing more-than-friendship went helter-skelter as the clock neared the new year.If you like to read light romances with happy ever after endings, you must read Robin's books. They're all great! Her writing just flows and it always immerses me completely in the story.4 3/4 stars! (Just because I wanted to shake Lyric so much during part of the book!)\n",
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "# Dense data should be passed and not a Sparse matrix\n",
    "clf_gnb.fit(train_x_vectors.toarray(), train_y) \n",
    "\n",
    "\n",
    "n=5\n",
    "print(test_x[n])\n",
    "print(test_y[n])\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[n].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excellent story dealing with what might have happened during the occupation of Rome. A must read for any war buff.\n",
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y) \n",
    "\n",
    "\n",
    "n=6\n",
    "print(test_x[n])\n",
    "print(test_y[n])\n",
    "\n",
    "clf_log.predict(test_x_vectors[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980769230769231\n",
      "0.6418269230769231\n",
      "0.6346153846153846\n",
      "0.8149038461538461\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuraies \n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors.toarray(), test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE', 'NEUTRAL', 'NEGATIVE']\n",
      "[0.8028169  0.         0.79310345]\n",
      "[0.63746959 0.         0.64608076]\n",
      "[0.59574468 0.         0.66666667]\n",
      "[0.82051282 0.         0.808933  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinjoy/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1493: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/home/sinjoy/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1493: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/home/sinjoy/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1493: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/home/sinjoy/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1493: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
     ]
    }
   ],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]\n",
    "print(labels)\n",
    "\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=labels))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, labels=labels))\n",
    "print(f1_score(test_y, clf_gnb.predict(test_x_vectors.toarray()), average=None, labels=labels))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average=None, labels=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE' 'POSITIVE' 'NEGATIVE' 'NEGATIVE']\n",
      "['POSITIVE' 'POSITIVE' 'NEGATIVE' 'NEGATIVE']\n",
      "['NEGATIVE' 'NEGATIVE' 'NEGATIVE' 'NEGATIVE']\n",
      "['POSITIVE' 'POSITIVE' 'NEGATIVE' 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "test_set = ['Very good book!', 'A must read for any war buff.',\n",
    "            'It is not bad', 'Horrible Waste of time'] \n",
    "\n",
    "test_set = vectorizer.transform(test_set)\n",
    "\n",
    "print(clf_svm.predict(test_set))\n",
    "print(clf_dec.predict(test_set))\n",
    "print(clf_gnb.predict(test_set.toarray()))\n",
    "print(clf_log.predict(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
